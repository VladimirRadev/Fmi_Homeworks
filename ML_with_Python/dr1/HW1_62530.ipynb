{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашно 1\n",
    "\n",
    "Линейна и логистична регресия.\n",
    "\n",
    "Предайте същата тетрадка като тази в заданието с нанесените от вас промени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mglearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_moons, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "warnings.filterwarnings(action='ignore', module='scipy', message='^internal gelsd')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1\n",
    "\n",
    "В заданието  имате данните отностно сърдечни заболявания, които са взети от [това състезание в kaggle](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction).\n",
    "Данните, които трябва да прочетете, са файлът `hearth.csv`\n",
    "\n",
    "1.1 Прочетете набора от данни с помощта на `pandas`. (*hint: read_csv*)\n",
    "\n",
    "1.2 След което разбийте данните на атрибути и целеви атрибут. в случая целевия атрибут е HeartDisease.\n",
    "\n",
    "1.3 Подгответе категорийните променливи, така че да могат да бъдат обработвани като индикатори. (*hint: get_dummies*)\n",
    "\n",
    "1.4 Разбийте данните на тренировъчно и тестово множество (като 30% от данните да са в тестовото множество).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1\n",
    "heart = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "X,y = heart.loc[:,heart.columns!='HeartDisease'] , heart.loc[:,heart.columns=='HeartDisease']\n",
    "heart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Age                918 non-null    int64  \n",
      " 1   RestingBP          918 non-null    int64  \n",
      " 2   Cholesterol        918 non-null    int64  \n",
      " 3   FastingBS          918 non-null    int64  \n",
      " 4   MaxHR              918 non-null    int64  \n",
      " 5   Oldpeak            918 non-null    float64\n",
      " 6   Sex_F              918 non-null    int64  \n",
      " 7   Sex_M              918 non-null    int64  \n",
      " 8   ChestPainType_ASY  918 non-null    int64  \n",
      " 9   ChestPainType_ATA  918 non-null    int64  \n",
      " 10  ChestPainType_NAP  918 non-null    int64  \n",
      " 11  ChestPainType_TA   918 non-null    int64  \n",
      " 12  RestingECG_LVH     918 non-null    int64  \n",
      " 13  RestingECG_Normal  918 non-null    int64  \n",
      " 14  RestingECG_ST      918 non-null    int64  \n",
      " 15  ExerciseAngina_N   918 non-null    int64  \n",
      " 16  ExerciseAngina_Y   918 non-null    int64  \n",
      " 17  ST_Slope_Down      918 non-null    int64  \n",
      " 18  ST_Slope_Flat      918 non-null    int64  \n",
      " 19  ST_Slope_Up        918 non-null    int64  \n",
      "dtypes: float64(1), int64(19)\n",
      "memory usage: 143.6 KB\n"
     ]
    }
   ],
   "source": [
    "# 1.3\n",
    "X = pd.get_dummies(data=X).replace({True: 1, False: 0})\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30,random_state=99)\n",
    "#X_test\n",
    "#y_test\n",
    "#print(\"Test subset percent: {}\".format(X_test.shape[0]/(X_train.shape[0] + X_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2\n",
    "\n",
    "2.1 Напревете логистична регресия, като я натренирате върху тренировъчните данни. Тествайте колко добре се справя върху тренировъчните и тестовите данни, използвайки функцията `.score()`.\n",
    "\n",
    "2.2 Тествайте как ще се промени резултата като добавите по-голяма регулизация.\n",
    "\n",
    "2.3 Тествайте как ще се промени резултата като добавите по-малка регулизация. \n",
    "\n",
    "2.4 Обеснете как интерпретирате резултатите от екпериментите си."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.86916\n",
      "Test score: 0.86594\n"
     ]
    }
   ],
   "source": [
    "# 2.1\n",
    "model = LogisticRegression(max_iter=10000).fit(X_train,y_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_train,y_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.86916\n",
      "Test score: 0.87319\n"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "model = LogisticRegression(C=10000,max_iter=10000).fit(X_train,y_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_train,y_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.86604\n",
      "Test score: 0.86232\n"
     ]
    }
   ],
   "source": [
    "# 2.3\n",
    "model = LogisticRegression(C=0.1,max_iter=10000).fit(X_train,y_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_train,y_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4\n",
    "- By default параметъра C е равен на 1\n",
    "- При покачване на параметъра C на 10000 получаваме най-добрата възможна оценка за генерализация за тестовите и тренировъчните данни от модела, а за стойности над 10000 вече оценките се влошават\n",
    "- При стойноста на параметъра C=0.1 оценките и на тестовите и на тренировъчните се влошават спрямо дефаултното C=1\n",
    "- Това се случва понеже , колкото по голямо C слагаме толкова повече алгоритъма за регуляризация кара моделът да научава трейнинг множеството и да не дава голямо наказание за екстремните характеристики и съответно когато му подадем данни от тестовото множество- да се справя по-добре. Докато когато намаляме C , караме регуляризацията да не се доверява на тези трейнинг данни толкова много и да наказва повече екстремните характеристики ( характеристиките с големи стойности) и така да не се fit-ва добре с трейнинг данните и съответно резултатите са по-ниски както за трейниннг така и за тестовото множество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 3\n",
    "\n",
    "3.1 Създайте модел за квадратични характеристики (`степен = 2`). Използвайте PolynomialFeatures, за да създадете данните.\n",
    "\n",
    "3.2 Повторете стъпките от Задача 2 върху квадратичните данни.\n",
    "\n",
    "3.3 Намерете броя на атрибутите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1\n",
    "X_poly=PolynomialFeatures(degree=2,include_bias=False,interaction_only=False).fit_transform(X)\n",
    "# X.shape\n",
    "# X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.86604\n",
      "Test score: 0.84420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vladi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 3.2.1\n",
    "X_poly_train,X_poly_test,y_poly_train,y_poly_test = train_test_split(X_poly,y,test_size=0.30,random_state=99)\n",
    "#X_poly_train.shape\n",
    "# X_poly_test.shape\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs',max_iter=100).fit(X_poly_train,y_poly_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_poly_train,y_poly_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_poly_test,y_poly_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.86916\n",
      "Test score: 0.85145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vladi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 3.2.2\n",
    "model = LogisticRegression(C=10,max_iter=100).fit(X_poly_train,y_poly_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_poly_train,y_poly_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_poly_test,y_poly_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.86760\n",
      "Test score: 0.84783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vladi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 3.2.3\n",
    "model = LogisticRegression(C=0.01,max_iter=100).fit(X_poly_train,y_poly_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_poly_train,y_poly_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_poly_test,y_poly_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.4\n",
    "-Получаваме най-добри резултати при C=10 и C=0.01 , т.е тренировъчната оценка и тестовата са максимално високи и близки една до друга. При увеличаване на C по-голямо от 10 резултатите започват да се влошават  както и при намаляване на C по-малко от 0.01 , т.е колкото по-строги са изискванията за регуляризация, толкова повече моделът ни не научава коректно тренировъчните данни и не генерализира добре ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attributes' count: 230\n"
     ]
    }
   ],
   "source": [
    "# 3.3\n",
    "print(\"The attributes' count: {}\".format(X_poly.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 4\n",
    "\n",
    "Повторете стъпките от задача 3 като преди това скалирате данните между 0 и 1. Сравнете резултата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1\n",
    "temp = MinMaxScaler().fit_transform(X)\n",
    "X_poly_scalled=PolynomialFeatures(degree=2,include_bias=False,interaction_only=False).fit_transform(temp)\n",
    "#temp.shape\n",
    "#X_poly_scalled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.89408\n",
      "Test score: 0.85507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vladi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 4.2.1\n",
    "X_poly_scalled_train,X_poly_scalled_test,y_poly_scalled_train,y_poly_scalled_test = train_test_split(X_poly_scalled,y,test_size=0.30,random_state=99)\n",
    "\n",
    "# X_poly_scalled_train.shape\n",
    "# X_poly_scalled_test.shape\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs',max_iter=100).fit(X_poly_scalled_train,y_poly_scalled_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_poly_scalled_train,y_poly_scalled_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_poly_scalled_test,y_poly_scalled_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.91121\n",
      "Test score: 0.84783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vladi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 4.2.2\n",
    "model = LogisticRegression(C=10,solver='lbfgs',max_iter=100).fit(X_poly_scalled_train,y_poly_scalled_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_poly_scalled_train,y_poly_scalled_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_poly_scalled_test,y_poly_scalled_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.87383\n",
      "Test score: 0.88043\n"
     ]
    }
   ],
   "source": [
    "# 4.2.3\n",
    "model = LogisticRegression(C=0.1,solver='lbfgs',max_iter=100).fit(X_poly_scalled_train,y_poly_scalled_train.values.ravel())\n",
    "print(\"Training score: {:1.5f}\".format(model.score(X_poly_scalled_train,y_poly_scalled_train)))\n",
    "print(\"Test score: {:1.5f}\".format(model.score(X_poly_scalled_test,y_poly_scalled_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.4\n",
    "- При C=10 получаваме най-добрите съвместни оценки на тренировъчна и тестова оценка , като с C по-голямо от 10 започваме да намаляваме от тестовата оценка и да покачваме тренировъчната (overfitting)\n",
    "- При C=0.1 получаваме най-добрите съвместни оценки на тренировъчна и тестова оценка , като с C по-малко от 0.01\n",
    "започваме да намаляваме от тренировъчната оценка и да покачваме тестовата и цялостно да правим резултатата по-лош (underfitting)\n",
    "- Със MinMaxScaller-a постигнахме това да сложим стойностите на характеристиките в интервал (0,1) и така да направим функцията на модела по-гладка , а моделът по-добре научаващ подадената информация (скрита регуляризация )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attributes' count: 230\n"
     ]
    }
   ],
   "source": [
    "# 4.3\n",
    "print(\"The attributes' count: {}\".format(X_poly_scalled.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
