{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашно 2\n",
    "\n",
    "Трениране и подобряване на модели\n",
    "\n",
    "Предайте същата тетрадка като тази в заданието с нанесените от вас промени. Кръстете файла с факултетния си номер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1\n",
    "\n",
    "В заданието  имате данните отностно сърдечни заболявания, които са взети от [тук](https://archive.ics.uci.edu/dataset/222/bank+marketing).\n",
    "Данните, които трябва да прочетете, са файлът `bank.csv`\n",
    "\n",
    "1.1 Прочетете набора от данни с помощта на `pandas`.\n",
    "\n",
    "1.2 След което разбийте данните на атрибути и целеви атрибут. в случая целевия атрибут е y.\n",
    "\n",
    "1.3 Подгответе категорийните променливи, така че да могат да бъдат обработвани като индикатори.\n",
    "\n",
    "1.4 Разбийте данните на тренировъчно и тестово множество (като 30% от данните да са в тестовото множество). \n",
    "\n",
    "Преди да ги разбиете вижте какъв е баланса между двата класа и помислете как трябва да ги разбиете(hint: stratification) \n",
    "\n",
    "1.5 Скалирайте данните така, че да имате средно 0 и стандартно отклонение 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import mglearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_moons, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "warnings.filterwarnings(action='ignore', module='scipy', message='^internal gelsd')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1\n",
    "data = pd.read_csv('bank.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2\n",
    "X, y = data.loc[:,data.columns!='y'] , data.loc[:,data.columns=='y']\n",
    "#print(\"{} {}\".format(X.shape,y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3\n",
    "X=pd.get_dummies(X).replace({True: 1, False: 0})\n",
    "y=y.replace({'no':0 , 'yes':1})\n",
    "#y['y'].value_counts().loc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30,stratify=y , random_state=619)\n",
    "# y_train.value_counts() #-> the proportion between the two classes should be around 0.13 (that means we stratify correct with the input data in y)\n",
    "# y_test.value_counts() #- > the proportion between the two classes should be around 0.13 (that means we stratify correct with the input data in y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler= StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)\n",
    "\n",
    "# X_train = pd.DataFrame(X_train,columns=['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
    "#        'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
    "#        'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
    "#        'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
    "#        'marital_divorced', 'marital_married', 'marital_single',\n",
    "#        'education_primary', 'education_secondary', 'education_tertiary',\n",
    "#        'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
    "#        'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
    "#        'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
    "#        'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
    "#        'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
    "#        'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
    "#        'poutcome_unknown'])\n",
    "# X_test = pd.DataFrame(X_test,columns=['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
    "#        'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
    "#        'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
    "#        'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
    "#        'marital_divorced', 'marital_married', 'marital_single',\n",
    "#        'education_primary', 'education_secondary', 'education_tertiary',\n",
    "#        'education_unknown', 'default_no', 'default_yes', 'housing_no',\n",
    "#        'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular',\n",
    "#        'contact_telephone', 'contact_unknown', 'month_apr', 'month_aug',\n",
    "#        'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun',\n",
    "#        'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
    "#        'poutcome_failure', 'poutcome_other', 'poutcome_success',\n",
    "#        'poutcome_unknown'])\n",
    "# np.mean(X_train.describe().loc['mean',:]) #should be 0\n",
    "# np.mean(X_test.describe().loc['mean',:]) # should be 0\n",
    "# np.mean(X_train.describe().loc['std',:]) # should be 1\n",
    "# np.mean(X_test.describe().loc['std',:]) # should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2 Дървета\n",
    "\n",
    "Използвайте крос-валидация с 5 гънки(5-fold cross validation), за да обучите и оптимизирате хиперпараметрите за дърво на решенията.\n",
    "\n",
    "Помислете внимателно как трябва да разбиете гънките при толкова небалансирани класове(hint: stratified k-fold cross-validation).\n",
    "\n",
    "Помислете как да оценявате модела не забравяйте, че точността не работи в този случай, защото данните са силно небалансирани. Имаме нужда от нещо, което съчетава прецизност и обхват(възвръщаемост).\n",
    "\n",
    "Направете grid search като изберете по 3 стойности за всеки от хипер параметрите\n",
    "* `max_depth`\n",
    "* `min_samples_leaf`\n",
    "* `max_leaf_nodes`\n",
    "\n",
    "Вижте как се представя алгоритъма върху тренировачните данни и кои са най-добрите хипер параметри."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "from sklearn.model_selection import cross_val_score ,StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=8, max_leaf_nodes=20, min_samples_leaf=5,\n",
      "                       random_state=619)\n",
      "Scores of Stratified5Fold cv: [0.88408015 0.89929821 0.89246387 0.88908795 0.88822558]\n",
      "Mean of Stratified5Fold cv: 0.8906311492316654\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "grid = {\n",
    "    \"max_depth\": [6,8,10],\n",
    "    \"min_samples_leaf\": [5, 10, 20],\n",
    "    \"max_leaf_nodes\": [10,20,30],\n",
    "}\n",
    "\n",
    "\n",
    "search = GridSearchCV(DecisionTreeClassifier(random_state=619),grid,cv=5)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "print(search.best_estimator_)\n",
    "\n",
    "\n",
    "#cross_val_score izpolzva StratifiedKFold cv po default pri classificaciq (kakto e v nashiq sluchai)\n",
    "scores = cross_val_score(search,X_train,y_train,cv=5,scoring=\"f1_weighted\") # pri silno nebalnsirani klasove f1_weightted e po-dobrata metrika\n",
    "print(\"Scores of Stratified5Fold cv: {}\".format(scores))\n",
    "print(\"Mean of Stratified5Fold cv: {}\".format(scores.mean()))\n",
    "\n",
    "#moje da e bavnichko za ichislenie poneje pravim mnogo iteracii za vsqka vuzmojna stoinost na grid (around 20sec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 3 Случайна гора\n",
    "\n",
    "Аналогично на предишната задача но този път със случайна гора\n",
    "\n",
    "Направете grid search като изберете по 3 стойности за всеки от хипер параметрите\n",
    "* `n_estimators`\n",
    "* `max_depth`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=8, n_estimators=5, random_state=619)\n",
      "Scores of Stratified5Fold cv: [0.87472489 0.84726208 0.84825395 0.85574752 0.84504841]\n",
      "Mean of Stratified5Fold cv: 0.8542073697515606\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid = {\n",
    "    \"n_estimators\": [5,10,20],\n",
    "    \"max_depth\": [4,6,8],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(RandomForestClassifier(random_state=619),grid,cv=5)\n",
    "search.fit(X_train,y_train.values.ravel())\n",
    "print(search.best_estimator_)\n",
    "\n",
    "\n",
    "#cross_val_score izpolzva StratifiedKFold cv po default pri classificaciq (kakto e v nashiq sluchai)\n",
    "scores = cross_val_score(search,X_train,y_train.values.ravel(),cv=5,scoring=\"f1_weighted\") # pri silno nebalnsirani klasove f1_weightted e po-dobrata metrika\n",
    "print(\"Scores of Stratified5Fold cv: {}\".format(scores))\n",
    "print(\"Mean of Stratified5Fold cv: {}\".format(scores.mean()))\n",
    "\n",
    "#moje da e bavnichko za ichislenie poneje pravim mnogo iteracii \n",
    "#za vsqka vuzmojna stoinost na grid i se skalira sprqmo stoinosta ( mnogo durveta = mnogo bavno , no po-dobri rezultati) (around 20sec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 4 SVM\n",
    "\n",
    "Аналогично на предишната задача но този път със svm\n",
    "\n",
    "Направете grid search като изберете по 3 стойности за всеки от хипер параметрите\n",
    "* `C`\n",
    "* `gamma`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, random_state=619)\n",
      "Scores of Stratified5Fold cv: [0.86460584 0.85783236 0.85569523 0.87472489 0.85850967]\n",
      "Mean of Stratified5Fold cv: 0.8622735974933692\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(SVC(random_state=619),grid,cv=5)\n",
    "search.fit(X_train,y_train.values.ravel())\n",
    "print(search.best_estimator_)\n",
    "\n",
    "\n",
    "#cross_val_score izpolzva StratifiedKFold cv po default pri classificaciq (kakto e v nashiq sluchai)\n",
    "scores = cross_val_score(search,X_train,y_train.values.ravel(),cv=5,scoring=\"f1_weighted\") # pri silno nebalnsirani klasove f1_weightted e po-dobrata metrika\n",
    "print(\"Scores of Stratified5Fold cv: {}\".format(scores))\n",
    "print(\"Mean of Stratified5Fold cv: {}\".format(scores.mean()))\n",
    "\n",
    "#moje da e bavnichko za ichislenie poneje pravim mnogo iteracii \n",
    "#za vsqka vuzmojna stoinost na grid i se skalira sprqmo stoinosta (around 1min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 5 \n",
    "\n",
    "Повторете задачи 2-4 като изполвате резултатите получени до сега за да избрете нови стойности на същите хипер параметри за които да правите нов grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=12, max_leaf_nodes=30, min_samples_leaf=5,\n",
      "                       random_state=619)\n",
      "Scores of Stratified5Fold cv: [0.88277926 0.90112718 0.87401765 0.88408015 0.88983769]\n",
      "Mean of Stratified5Fold cv: 0.886368386552564\n"
     ]
    }
   ],
   "source": [
    "# 5.2 \n",
    "\n",
    "# stari_grid = {\n",
    "#     \"max_depth\": [6,8,10],\n",
    "#     \"min_samples_leaf\": [5, 10, 20],\n",
    "#     \"max_leaf_nodes\": [10,20,30],\n",
    "# }\n",
    "\n",
    "grid = {\n",
    "    \"max_depth\": [8,10,12],\n",
    "    \"min_samples_leaf\": [5,15,20],\n",
    "    \"max_leaf_nodes\": [30,40,50],\n",
    "}\n",
    "\n",
    "\n",
    "search = GridSearchCV(DecisionTreeClassifier(random_state=619),grid,cv=5)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "print(search.best_estimator_)\n",
    "\n",
    "\n",
    "#cross_val_score izpolzva StratifiedKFold cv po default pri classificaciq (kakto e v nashiq sluchai)\n",
    "scores = cross_val_score(search,X_train,y_train,cv=5,scoring=\"f1_weighted\") # pri silno nebalnsirani klasove f1_weightted e po-dobrata metrika\n",
    "print(\"Scores of Stratified5Fold cv: {}\".format(scores))\n",
    "print(\"Mean of Stratified5Fold cv: {}\".format(scores.mean()))\n",
    "\n",
    "#moje da e bavnichko za ichislenie poneje pravim mnogo iteracii za vsqka vuzmojna stoinost na grid (around 30sec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стигнахме до изводът , че предните стойности са оптимални за тези данни, и са по-добри отколкото новите . Като държим повече листа, с по-голяма дълбочина и по-малко примери за тестване преди рязане на дървото достигнахме до изводът че - получаваме по-ниски резултати отколкото преди"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=9, n_estimators=50, random_state=619)\n",
      "Scores of Stratified5Fold cv: [0.87621106 0.85252849 0.86201376 0.86921685 0.86218385]\n",
      "Mean of Stratified5Fold cv: 0.8644308015370346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5.3\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# stari_grid = {\n",
    "#     \"n_estimators\": [5,10,20],\n",
    "#     \"max_depth\": [4,6,8],\n",
    "# }\n",
    "\n",
    "grid = {\n",
    "    \"n_estimators\": [30,40,50],\n",
    "    \"max_depth\": [5,7,9],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(RandomForestClassifier(random_state=619),grid,cv=5)\n",
    "search.fit(X_train,y_train.values.ravel())\n",
    "print(search.best_estimator_)\n",
    "\n",
    "\n",
    "#cross_val_score izpolzva StratifiedKFold cv po default pri classificaciq (kakto e v nashiq sluchai)\n",
    "scores = cross_val_score(search,X_train,y_train.values.ravel(),cv=5,scoring=\"f1_weighted\") # pri silno nebalnsirani klasove f1_weightted e po-dobrata metrika\n",
    "print(\"Scores of Stratified5Fold cv: {}\".format(scores))\n",
    "print(\"Mean of Stratified5Fold cv: {}\".format(scores.mean()))\n",
    "\n",
    "#moje da e bavnichko za ichislenie poneje pravim mnogo iteracii \n",
    "#za vsqka vuzmojna stoinost na grid i se skalira sprqmo stoinosta ( mnogo durveta = mnogo bavno , no po-dobri rezultati) (around 20sec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаваме по-добри резултати , отколкото преди с новите хиперпараметри, но това звучи логично , колкото повече дървета в гората, толкова по-добре можем да си направим преценка за резултата. Както и по-дълбока дълбочина на дървото ни отвежда до по-голяма склонност за научаване по-добре на тренировъчните данни\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, random_state=619)\n",
      "Scores of Stratified5Fold cv: [0.83054257 0.83054257 0.8813141  0.83054257 0.88270282]\n",
      "Mean of Stratified5Fold cv: 0.8511289248422859\n"
     ]
    }
   ],
   "source": [
    "# 5.4\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# стари_grid = {\n",
    "#     \"C\": [0.1, 1, 10],\n",
    "#     \"gamma\": [\"scale\", \"auto\"],\n",
    "# }\n",
    "grid = {\n",
    "    \"C\": [10, 100,0.00001],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(SVC(random_state=619),grid,cv=5)\n",
    "search.fit(X_train,y_train.values.ravel())\n",
    "print(search.best_estimator_)\n",
    "\n",
    "\n",
    "#cross_val_score izpolzva StratifiedKFold cv po default pri classificaciq (kakto e v nashiq sluchai)\n",
    "scores = cross_val_score(search,X_train,y_train.values.ravel(),cv=5,scoring=\"f1_weighted\") # pri silno nebalnsirani klasove f1_weightted e po-dobrata metrika\n",
    "print(\"Scores of Stratified5Fold cv: {}\".format(scores))\n",
    "print(\"Mean of Stratified5Fold cv: {}\".format(scores.mean()))\n",
    "\n",
    "#moje da e bavnichko za ichislenie poneje pravim mnogo iteracii \n",
    "#za vsqka vuzmojna stoinost na grid i se skalira sprqmo stoinosta (around 50sec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 6\n",
    "\n",
    "Сравнете как се предстявят всички модели и изберете кой е най-добрия\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#6**<br/>\n",
    "Като заключение след проведените тестове , можем да считаме че **DecisionTreeClassifier** се справя най- добре с подадените данни и спрямо cross-validaciqта и хиперпараметрите max_depth=8, max_leaf_nodes=20, min_samples_leaf=5 получаваме среден резултат от 5те итерации : *0.8906311492316654* \n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "Като втори най-добър е **RandomForestClassifier** с резултат от 5те итерации на крос валидацията : *0.8644308015370346*\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "И най - зле се представя **SVC**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
